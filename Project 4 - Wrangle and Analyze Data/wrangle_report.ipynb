{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Wrangle and Analyze Twitter Data\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* ### [Introduction](#intro)\n",
    "* ### [Project details](#project_details)\n",
    "* ### [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we'll work through the entire Data wrangling and Analysis process, starting from gathering the right piece of data from a variety of sources and in a variety of formats, assessing its quality and tidiness, then clean it.\n",
    "<br>\n",
    "\n",
    "In this report, we'll document our wrangling efforts, then Showcase the Analysis and visualisations in another report. We will wrangle data about [@dog_rates](https://twitter.com/dog_rates) from different sources, [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs) is a Twitter account\tthat rates people's\tdogs with a humorous comment about the dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project_details'></a>\n",
    "## Project details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project consisted of three main tasks, each task will be documented next in detail.  \n",
    "* ### [Gathering Data](#gather)\n",
    "* ### [Assessing Data](#assess)\n",
    "* ### [Cleaning Data](#clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the project this step is considered the hardest one, knowing the right piece of data and the right place to get usually takes time and effort, virtually we are lucky this time to get provided with part of data and sources to get the others.The data for this project is composed of three separate datasets collected as follows:\n",
    "1. **twitter archive file:** downloaded manually and directly from Udacity as comma separated file.\n",
    "2. **image predictions file:** downloaded programmatically with `request` library as tab separated file.\n",
    "3. **Twitter API:** query the Twitter API with Python's library`Tweepy ` to get additional data as JSON format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='asses'></a>\n",
    "### Assessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Gathering Data we'll asses it's quality and structure, and that was done in two ways:\n",
    "* **Visually:** \n",
    "> Using Google sheet (or any other software) to identify and categorize common data quality and tidiness issues in the data that we gathered before, by inspecting data visually we could notice some quality issue that are related with completeness like missing data in dog stages, or data validity like the timestamp column with trailing zeros.   \n",
    "\n",
    "* **Programmaticly:**\n",
    ">Pragrammatic assessment is more effective than visual asseement, using pandas function like `.info()`, `value_counts()`, `.describe()` will gives us all columns, data type, statistic summary about our data, and that serves to check data accuracy, validity and consistency, example of issue detected programmatically is columns data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the assessment done before will be converted to code in order to clean the data, we often make copy of each piece of data before start cleaning operations.  \n",
    "<br>\n",
    "\n",
    "Cleaning data consists of three steps:\n",
    "1. **Define:** convert the  assessment into cleaning tasks something like pseudo code.\n",
    "2. **Code:** translate the pseudo code into real code and run it.\n",
    "3. **Test:** test the code to check the cleaning worked as supposed, this usually done by using  assessment functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Case, some cleaning tasks were easy like changing data type, and others were challenging like removing the urls form text text or removing the retweets, Note that cleaning all issues in these datasets is time consuming so we only considered 8 quality issues and 2 for tidiness issues.\n",
    "\n",
    "The final dataset was stored as csv file `.csv` for the next step which is Analysis and visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of what we have done so far:**\n",
    "* Gathered our datasets from 3 different sources.  \n",
    "* Assessed all datasets visually and programmatically.  \n",
    "* Documented the identified its issues (quality and tidiness).  \n",
    "* Cleaned the dataset by converting the assessments to code (Define, Code, Test).\n",
    "* Stored the final dataset int `.csv` file for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
